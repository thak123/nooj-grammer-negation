{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Collecting seqeval[cpu]\n",
      "  Using cached seqeval-0.0.12.tar.gz (21 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/gthakkar/.local/lib/python2.7/site-packages (from seqeval[cpu]) (1.16.6)\n",
      "Collecting Keras>=2.2.4\n",
      "  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "Collecting tensorflow>=1.13.1\n",
      "  Downloading tensorflow-2.1.0-cp27-cp27mu-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 6.8 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14\n",
      "  Downloading scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.8 MB 78 bytes/s  0:00:0141�██████████| 24.8 MB 44 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8.tar.gz (289 kB)\n",
      "\u001b[K     |████████████████████████████████| 289 kB 24.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /home/gthakkar/.local/lib/python2.7/site-packages (from Keras>=2.2.4->seqeval[cpu]) (1.14.0)\n",
      "Collecting h5py\n",
      "  Downloading h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 19.1 MB/s eta 0:00:01      | 1.8 MB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 34.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Using cached Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.11.3-cp27-cp27mu-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 31.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.28.1-cp27-cp27mu-manylinux2010_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 32.9 MB/s eta 0:00:01��████████████████████▋ | 2.7 MB 32.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-2.3.2.tar.gz (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 832 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py2-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 702 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.0-py2-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 11.8 MB/s eta 0:00:01████▍       | 2.9 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel; python_version < \"3\" in /usr/lib/python2.7/dist-packages (from tensorflow>=1.13.1->seqeval[cpu]) (0.29.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting mock>=2.0.0; python_version < \"3\"\n",
      "  Downloading mock-3.0.5-py2.py3-none-any.whl (25 kB)\n",
      "Collecting backports.weakref>=1.0rc1; python_version < \"3.4\"\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting functools32>=3.2.3; python_version < \"3\"\n",
      "  Downloading functools32-3.2.3-2.tar.gz (31 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting enum34>=1.1.6; python_version < \"3.4\"\n",
      "  Downloading enum34-1.1.10-py2-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python2.7/dist-packages (from protobuf>=3.8.0->tensorflow>=1.13.1->seqeval[cpu]) (20.7.0)\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\"\n",
      "  Downloading futures-3.3.0-py2-none-any.whl (16 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.14.1-py2.py3-none-any.whl (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 729 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.1.1-py2.py3-none-any.whl (87 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/gthakkar/.local/lib/python2.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=1.13.1->seqeval[cpu]) (2.22.0)\n",
      "Collecting funcsigs>=1; python_version < \"3.3\"\n",
      "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 19.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gthakkar/.local/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=1.13.1->seqeval[cpu]) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/gthakkar/.local/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=1.13.1->seqeval[cpu]) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/gthakkar/.local/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=1.13.1->seqeval[cpu]) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/gthakkar/.local/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=1.13.1->seqeval[cpu]) (1.25.7)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 307 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: seqeval, keras-applications, pyyaml, absl-py, wrapt, opt-einsum, gast, functools32, termcolor\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py2-none-any.whl size=8511 sha256=248431f923f0dcbe6b3d4fad0668447794eeed49cc0dbd26a2e7bf47a292aaa4\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/2a/13/2c/e074d99dbecbf11dc9e8c00f7ca71050144342d7d6e1e9aee4\n",
      "  Building wheel for keras-applications (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-applications: filename=Keras_Applications-1.0.8-py2-none-any.whl size=50949 sha256=146ce4a8b74d56dcf8c0e72f056d1680e245f29243e4d4fe1b2227571f71f68a\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/71/a0/64/e2e0c93740e0460f4b7f036141b7c73b5e44ff38f690ddff9f\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp27-cp27mu-linux_x86_64.whl size=46867 sha256=ea6224d54774e94518389e0b08e8f00566a2af6e935617dc4e099393dae97877\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/d1/d5/a0/3c27cdc8b0209c5fc1385afeee936cf8a71e13d885388b4be2\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py2-none-any.whl size=119310 sha256=00817be39f417d7bba8cf048c76356d0f44f34f8d3d4d3ae83a97daf86004c2f\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/37/83/b0/40d9e9f3d5a7021dfda2f3ea1f0088235679cd7747761c7b93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp27-cp27mu-linux_x86_64.whl size=64118 sha256=d8dc8849a80de90a5e37a5d872fcdd971b8c7004339f0c7aaf705e0635ad5d14\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/5b/d8/8e/81a83cb5321b940a954996f5b57fddc8976e712b3ac3a1a54b\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-2.3.2-py2-none-any.whl size=52291 sha256=437cdb52e9a92fcf720fe37e430fb9abcde6af85247bcc214b0075eff8f1a1f2\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/ef/c4/c2/d0b07dd2a54f4d583a5de0e6ce5eb7a1832961b9a10d1ec953\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py2-none-any.whl size=7567 sha256=8607d91095452e7749d934a08a0456998f3067f082048bcc1ed4afc2cd14f935\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/0f/10/f7/29260ef8a721b90061c8c70a4f0130a64036e8dafe15acc097\n",
      "  Building wheel for functools32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for functools32: filename=functools32-3.2.3.post2-py2-none-any.whl size=10936 sha256=7df6aed4652db02e870e79ed6a83e06b91b2660654c85a11f730ca3662af7362\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/c2/ea/a3/25af52265fad6418a74df0b8d9ca8b89e0b3735dbd4d0d3794\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py2-none-any.whl size=5680 sha256=7410ea4b8e99d7bb506d7946e3d39866fdbd096e70dc5c7fd2aa63f416b374ec\n",
      "  Stored in directory: /home/gthakkar/.cache/pip/wheels/48/54/87/2f4d1a48c87e43906477a3c93d9663c49ca092046d5a4b00b4\n",
      "Successfully built seqeval keras-applications pyyaml absl-py wrapt opt-einsum gast functools32 termcolor\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement scipy==1.2.2; python_version < \"3\", but you'll have scipy 1.2.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: markdown 3.1.1 has requirement setuptools>=36, but you'll have setuptools 20.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.1.0 has requirement setuptools>=41.0.0, but you'll have setuptools 20.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-auth 1.14.1 has requirement setuptools>=40.3.0, but you'll have setuptools 20.7.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy, h5py, keras-applications, pyyaml, keras-preprocessing, Keras, protobuf, enum34, absl-py, futures, grpcio, wrapt, opt-einsum, google-pasta, tensorflow-estimator, gast, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, werkzeug, tensorboard, astor, funcsigs, mock, backports.weakref, functools32, termcolor, tensorflow, seqeval\n",
      "Successfully installed Keras-2.3.1 absl-py-0.9.0 astor-0.8.1 backports.weakref-1.0.post1 cachetools-3.1.1 enum34-1.1.10 funcsigs-1.0.2 functools32-3.2.3.post2 futures-3.3.0 gast-0.2.2 google-auth-1.14.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.28.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 mock-3.0.5 oauthlib-3.1.0 opt-einsum-2.3.2 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyyaml-5.3.1 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.2.3 seqeval-0.0.12 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "#Install seqeval\n",
    "!pip install seqeval[cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from seqeval.metrics import accuracy_score\n",
    ">>> from seqeval.metrics import classification_report\n",
    ">>> from seqeval.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    ">>> y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    ">>> y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    ">>>\n",
    "# print(f1_score(y_true, y_pred))\n",
    "# 0.50\n",
    "# >>> accuracy_score(y_true, y_pred)\n",
    "# 0.80\n",
    "\n",
    "# >>> classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Nooj output to Conll format -> check which format is best => we used the annotated text format\n",
    "# Read the Conan Doyale Negation Corpus\n",
    "# pass the both the representations through grader\n",
    "# for each sentence, prediction calculate the score and dispay the error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same for the validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsave upon those not infrequent occasions when he was up all night ,/<save,save,WF>#<upon,upon,WF>#<those,those,WF>#<NEG-CUE#<not,,WF>#>#<infrequent,infrequent,WF>#<occasions,occasions,WF>#<when,when,WF>#<he,he,WF>#<was,was,WF>#<up,up,WF>#<all,all,WF>#<night,night,WF>#<',',,WF>#\t\n",
      "\n",
      "\tand I had given him no sign of my occupation ./<and,and,WF>#<I,I,WF>#<had,had,WF>#<given,given,WF>#<him,him,WF>#<NEG-CUE#<no,,WF>#>#<sign,sign,WF>#<of,of,WF>#<my,my,WF>#<occupation,occupation,WF>#<'.',,WF>#\t\n",
      "\n",
      "\tSince we have been so unfortunate as to miss him and have no notion of his errand ,/<Since,Since,WF>#<we,we,WF>#<have,have,WF>#<been,been,WF>#<so,so,WF>#<unfortunate,unfortunate,WF>#<as,as,WF>#<to,to,WF>#<miss,miss,WF>#<him,him,WF>#<and,and,WF>#<have,have,WF>#<NEG-CUE#<no,,WF>#>#<notion,notion,WF>#<of,of,WF>#<his,his,WF>#<errand,errand,WF>#<',',,WF>#\t\n",
      "\n",
      "\tIt may be that you are not yourself luminous ,/<It,It,WF>#<may,may,WF>#<be,be,WF>#<that,that,WF>#<you,you,WF>#<are,are,WF>#<NEG-CUE#<not,,WF>#>#<yourself,yourself,WF>#<luminous,luminous,WF>#<',',,WF>#\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"../565.txt\") as input_file:\n",
    "    for index,line in enumerate(input_file):\n",
    "        print(line)\n",
    "        if index >2:  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
