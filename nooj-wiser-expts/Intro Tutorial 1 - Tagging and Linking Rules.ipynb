{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to WISER, Part 1: Tagging and Linking Rules\n",
    "\n",
    "Welcome to WISER (*Weak and Indirect Supervision for Entity Recognition*), a system for training sequence-to-sequence models, particularly neural networks for named entity recognition (NER) and related tasks. WISER uses *weak supervision* in the form of rules to train these models, as opposed to hand-labeled training data.\n",
    "\n",
    "In this first part of the tutorial, we will be writing tagging and linking rules to identify award names, media performances from a Wikipedia text corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "WISER is an add-on to [AllenNLP](http://allennlp.org), a great framework for natural language processing. That means we can use their tools for working with data.\n",
    "\n",
    "Let's start by loading the Media dataset, a new dataset we created just for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [00:00, 17766.34it/s]\n",
      "144it [00:00, 10419.91it/s]\n",
      "235it [00:00, 7167.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-len 699\n",
      "dev-len 144\n",
      "test-len 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from wiser.data.dataset_readers import StoriesDatasetReader\n",
    "\n",
    "dataset_reader = StoriesDatasetReader()\n",
    "\n",
    "train_data = dataset_reader.read('data/unlabelled_conandoyle_train.csv')\n",
    "dev_data = dataset_reader.read('data/labelled_conandoyle_dev.csv')\n",
    "test_data = dataset_reader.read('data/labelled_conandoyle_test.csv')\n",
    "\n",
    "print(\"train-len\",len(train_data))\n",
    "print(\"dev-len\",len(dev_data))\n",
    "print(\"test-len\",len(test_data))\n",
    "\n",
    "# We must merge all partitions to apply the rules\n",
    "data = train_data + dev_data + test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to use WISER with other data sets is to implement a new subclass of AllenNLP's [DatasetReader](https://allenai.github.io/allennlp-docs/api/allennlp.data.dataset_readers.dataset_reader.html#allennlp.data.dataset_readers.dataset_reader.DatasetReader). We have some additional examples in the package `wiser.data.dataset_readers`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data\n",
    "Once the data is loaded, we can use a WISER class called `Viewer` to inspect the sentences and tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from wiser.viewer import Viewer\n",
    "Viewer(dev_data, height=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the left and right buttons to flip through the items in `dev_data`, each of which is an AllenNLP [`Instance`](https://allenai.github.io/allennlp-docs/api/allennlp.data.instance.html#allennlp.data.instance.Instance). The highlighted spans are the entities, and you can hover over each one with your cursor to see whether it is an award (**AWD**), or a media performance **PERF**.\n",
    "\n",
    "The drop-down menu selects which source of labels is displayed. Currently only the gold labels from the benchmark are available, but we will add more soon.\n",
    "\n",
    "Advance to the instance at index 1 to see an example with multiple entities of different classes. You can access the underlying tags too by hovering over particular tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that WISER uses the [IOB1 tagging scheme](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), meaning that entities are represented as consecutive tags beginning with **I**. Many data sets use subsequent characters for different classes, for example **-AWD** for awards and **-PERF** for movies, T.V. shows, or theatre plays. The **O**, or other tag, means that the token is not part of an entity. There is also a special set of tags beginning with **B** (like those beginning with **I**) that are used to start a new entity that immediately follows another of the same class without an **O** tag in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Rules\n",
    "Tagging rules are functions that map unlabeled text instances to sequences of labels. We can define our own tagging rules by writing small functions that look at sequences of instance tokens, and vote on their correponding tags. Let's first import the ``TaggingRule`` class from ``wiser.rules``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.rules import TaggingRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Simple Tagging Rules\n",
    "From inspecting instance 11, we know tokens proper nouns followed by a year between parentheses are likely tagged as movies. For instance, the token ``Friends`` in the span ``Friends (1994 - 2004)`` should be tagged **I-PERF**. Let's  write our first tagging rule to reflect this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class MovieYear(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        # Creates a list of tokens\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        \n",
    "        # Initializes a list of ABS (abstain) label votes \n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        for i in range(len(tokens)-2):    \n",
    "            # Tags proper nouns followed by a number between parentheses\n",
    "            if tokens[i].istitle() and tokens[i+1] == '(' and tokens[i+2].isdigit():\n",
    "                labels[i] = 'I-PERF'\n",
    "               \n",
    "        # Returns the modified label vote list\n",
    "        return labels\n",
    "\n",
    "# Applies the tagging rule to all dataset instances \n",
    "tr = MovieYear()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write a tagging rule to identify award categories like ``for Oustanding Lead Actress`` in award spans such as ``BAFTA Award for Oustanding Lead Actress``. Categories are generally preceded by capitalized letters, and follow with the strings ``for Oustanding`` or ``for Best``. Please refer instance at index 1 for an example of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class AwardCategory(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        for i in range(len(tokens)-2):\n",
    "            if tokens[i].istitle() and tokens[i+1] == 'for' and tokens[i+2] in {'Best', 'Oustanding'}:\n",
    "                labels[i+1] = 'I-AWD'\n",
    "                labels[i+2] = 'I-AWD'\n",
    "               \n",
    "        return labels\n",
    "\n",
    "tr = AwardCategory()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Function Helpers\n",
    "\n",
    "You can also use existing tagging functions and helpers available at `wiser.rules`. The ``DictionaryMatcher`` is a tagging function helper that allows us to quickly create a new rule that votes on any element found in a set of characters or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.rules import DictionaryMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any token spelling ``Award`` , ``Awards``, ``Prize`` or ``Cup`` should be tagged as an award. Be mindful of capitalization, since awards are proper nouns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "award_keywords = [['Award'], ['Awards'], ['Prize'], ['Cup']]\n",
    "                  \n",
    "tr = DictionaryMatcher(\"AwardKeywords\", terms=award_keywords, i_label=\"I-AWD\", uncased=False)\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good trick to developing efficient sequence taggers is to also generate negative supervision in the form of **O** tags. We can write the first function of this kind to tag some punctuations signs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439544e89e6a403caae404a7d6869d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "non_entity_punctuation_chars = {'.', ';', '(', ')', '!', \"\\\\\", ',', '--', '``'}\n",
    "\n",
    "tr = DictionaryMatcher(\"Non-EntityPunctuation\", terms=non_entity_punctuation_chars, i_label=\"O\")\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend going over the data and identifying a few false positive tokens. That is, tokens that are similar to entities but are not (e.g., capitalized tokens such as studio names). We will also write a `DictionaryMatcher` identify some common false positives and tag them as such:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_false_positives = [['network'], ['netflix'], ['hulu'], ['bbc'], ['fox'], \n",
    "                          ['disney'], ['hbo'], ['CBS'], ['channel'], ['american'], \n",
    "                         ['showtime'], ['productions'], ['TV']]\n",
    "\n",
    "tr = DictionaryMatcher(\"CommonFalsePositives\", terms=common_false_positives, i_label=\"O\", uncased=True)\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66bff07c2794d38b0f33b5d2d273caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "common_false_positives = [['And'],['But']]\n",
    "\n",
    "tr = DictionaryMatcher(\"CommonFalsePositives\", \n",
    "                       terms=common_false_positives, \n",
    "                       i_label=\"O\", \n",
    "                       uncased=False)\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8090be50e994fdeb15ea8f0b6ee3ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RULE 1. MARK ALL NEGATION CUES.\n",
    "common_true_positives_implicits_cue = [['not'],['no'],['n\\'t'],\n",
    "                                       ['never'],['absence'],['without'],\n",
    "                                       ['nobody'],['nowhere'],['nothing'],\n",
    "                                       [\"except\"],[\"fail\"],['none'],\n",
    "                                       ['neither'],['nor']\n",
    "                                      ]\n",
    "\n",
    "tr = DictionaryMatcher(\"CommonTruePositivesImplicitsCue\", \n",
    "                       terms=common_true_positives_implicits_cue, \n",
    "                       i_label=\"I-cue\", \n",
    "                       uncased=True)\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee1fcbf812a4ad7a53a26a6934ff2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RULE 2: MARK IMPLICIT SCOPE CUES\n",
    "# TODO breathlessness lifeless careless useless purposeless motionless helpless harmless noiselessly uneasiness shelterless  \n",
    "# check if the word is surrounded by non word characters \n",
    "\n",
    "#%% unconventional  impatient uncommonly unmistakable \n",
    "#%% unnatural insufferable  inadmissable insensibly undoubtedly sapless \n",
    "# For these guys check if the words above and below are not function words or puncts\n",
    "common_true_positives_implicits_scope = [['unknown'],['unambitious'],['unpractical'],\n",
    "                                         ['unable'],['unhappy'],['untimely'],\n",
    "                                         ['untenanted'],['impenetrable'],['unsafe'],\n",
    "                                         ['immaterial'],['uneducated'],['indiscreet'],\n",
    "                                         ['unpleasant'],['impossible'],['inexplicable'],\n",
    "                                         [\"disconnected\"],['imprudent'],['undeniable'],\n",
    "                                         ['unmistakable'],['uncontrollable'],['unjustifiable'],\n",
    "                                         ['impassable'],['uncanny'],['uncommon'],['unconcernedly'],\n",
    "                                         ['unfortunate'],['unfruitful'],\n",
    "                                         ['uninteresting'],['uneasy'],['unemotional'],\n",
    "                                         ['disapprobation'],['impatient'],['unfounded'],\n",
    "                                         ['unexpected'],['irresolute'],['displeasure'],\n",
    "                                         ['disfavour'],['inscrutable'],\n",
    "                                         ['inconvenient'],['immutable'],['inhospitable'],\n",
    "                                         ['irrevocable'],['unconcerned'],['unpleasant'],\n",
    "                                         ['unmitigated'],['unlikely'],['unnatural'],\n",
    "                                         ['unconscious'],['unexpected'],\n",
    "                                         \n",
    "                                         [\"breathlessness\"],[\"lifeless\"],[\"careless\"],\n",
    "                                         [\"useless\"],[\"purposeless\"],[\"motionless\"],\n",
    "                                         [\"helpless\"],[\"harmless\"],[\"noiselessly\"],\n",
    "                                         [\"uneasiness\"],[\"shelterless\"]\n",
    "                                         \n",
    "                                        ]\n",
    "\n",
    "tr = DictionaryMatcher(\"CommonTruePositivesImplicitsScope\", \n",
    "                       terms=common_true_positives_implicits_scope, \n",
    "                       i_label=\"I-scope\", \n",
    "                       uncased=True)\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"by\"==\"By\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef3fc0c0988462aaef0feaa7e40f618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MARK PHRASES 1. TRIGRAM\n",
    "class TrigramNegationCue(TaggingRule):\n",
    "    negation_cues = [\"by no means\",\"on the contrary\",\"not for the world\",\"nothing at all\"]\n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        for i in range(len(tokens)-3):\n",
    "            for j in self.negation_cues:\n",
    "                cues = j.split()\n",
    "                if tokens[i].lower()==cues[0] and tokens[i+1].lower() == cues[1] and tokens[i+2].lower()==cues[2]:\n",
    "                    labels[i] = 'I-cue'\n",
    "                    labels[i+1] = 'I-cue'\n",
    "                    labels[i+2] = 'I-cue'\n",
    "\n",
    "        return labels\n",
    "\n",
    "tr = TrigramNegationCue()\n",
    "tr.apply(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532e1c36575c4f36b3f3d7251037b91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MARK PHRASES 2. BIGRAM with NT\n",
    "class BigramNegationCueNT(TaggingRule):\n",
    "    primary_cue =\"n't\"\n",
    "    negation_cues =  [\"ca\",\"could\",\"did\",\"do\",\"had\",\"have\",\"is\",\"was\",\"wo\",\"would\"]\n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        for i in range(len(tokens)-2):\n",
    "            for j in self.negation_cues:\n",
    "                if tokens[i].lower()==j and tokens[i+1].lower() == self.primary_cue:\n",
    "                    labels[i] = 'I-scope'\n",
    "                    labels[i+1] = 'I-cue'\n",
    "\n",
    "        return labels\n",
    "\n",
    "tr = BigramNegationCueNT()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurish/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gaurish/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gaurish/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gaurish/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gaurish/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gaurish/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package benepar_en to\n",
      "[nltk_data]     /home/gaurish/nltk_data...\n",
      "[nltk_data]   Package benepar_en is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import benepar\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "benepar.download('benepar_en')\n",
    "spacy.prefer_gpu(0)\n",
    "nlp = spacy.load('en_core_web_sm',disable=[\"ner\"])\n",
    "nlp.add_pipe(BeneparComponent('benepar_en'))\n",
    "from nltk.tree import Tree\n",
    "from nltk.tree import ParentedTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-00e85022cfbc>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-00e85022cfbc>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    neg_cue_word =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def scope_candidate(sent,neg_cue_word=None):\n",
    "    ptree = ParentedTree.fromstring(sent._.parse_string)\n",
    "    leaf_values = ptree.leaves()\n",
    "    print(leaf_values)\n",
    "    neg_cue_word =\n",
    "    if neg_cue_word in leaf_values:\n",
    "        leaf_index = leaf_values.index(neg_cue_word)\n",
    "        tree_location = ptree.leaf_treeposition(leaf_index)\n",
    "        print(tree_location)\n",
    "        print(ptree[tree_location])\n",
    "\n",
    "    return set(ptree[tree_location[:-3]].leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScopeConstituencyKeywords(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "        \n",
    "        doc = nlp(\" \".join(tokens))\n",
    "        sent = list(doc.sents)[0]\n",
    "        \n",
    "        implicit_cue_positives = [t for t in instance['WISER_LABELS']['CommonTruePositivesImplicitsCue']]\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            if implicit_cue_positives[i] ==\"I-cue\":\n",
    "                candidates = scope_candidate(sent, tokens[i])\n",
    "                # get the window length\n",
    "                candidate_len = len(candidates)\n",
    "                # create a window around the index where the neg-cue is found\n",
    "                \n",
    "#             if tokens[i].lower() in movie_keywords:\n",
    "#                 \"\"\"\n",
    "#                     We will only tag a word as a movie if \n",
    "#                     the CommonFalsePositives asbtained from voting it.\n",
    "                    \n",
    "#                     We also want to avoid award names \n",
    "#                     like \"... Musical Drama\", etc.\n",
    "#                 \"\"\" \n",
    "                \n",
    "#                 # Keywords followed by movies (e.g., Kung-Fu Panda franchise)\n",
    "#                 if i < len(tokens) and tokens[i+1].istitle() and false_positives[i+1] == 'ABS':\n",
    "#                     if tokens[i+1].lower() not in movie_keywords:\n",
    "#                         labels[i+1] = 'I-PERF'\n",
    "                       \n",
    "#                 # Movies followed by keywords \n",
    "#                 elif i > 0 and tokens[i-1].istitle() and false_positives[i-1] == 'ABS':\n",
    "#                     if tokens[i-1].lower() not in movie_keywords:\n",
    "#                         labels[i-1] = 'I-PERF'\n",
    "        return labels\n",
    "\n",
    "tr = MovieKeywords()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no\tB_cue\n",
    "- one\tB_scope\n",
    "- but\tI_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate rule for ['neither'],['nor'] -> Update the rules from NOOj if available or I dunno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at previously tagged rules with nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I have devised following rules\n",
    "* 1. Consituency parser = Looks at the the negated words in a tree takes the parent and marks them as scope also need neg-cues to act as anchor points\n",
    "* 2. Implicit negation \n",
    " - direct take the word mark it as scope and above and below two words -> Baseline => take care of above and below words for punctuations and conjunctions\n",
    " - can we improve the baseline with consituency parser ?\n",
    " \n",
    "## Cases to handle last \n",
    "- 3. Pos tag rules to skip the annotation => It is something\n",
    "- 4. Need to check which cases and becomes O and otherwise \n",
    "\n",
    "\n",
    "\n",
    "- Linking rules are ineffective (e.g. low accuracy or coverage).\n",
    "- Suboptimal generative model hyperparameters\n",
    "- Lack of negative supervision (e.g. need to add more tagging rules that vote on 'O' tags)\n",
    "\n",
    "We will also be releasing a FAQ of common questions and debugging tips, so hopefully more people can use these tricks to improve their models.\n",
    "\n",
    "A precision of 0.7349 looks really good! With that score, I would expect the neural tagger to improve recall by a few points.\n",
    "\n",
    "The HMM should be a tad faster than the link-HMM, and the Naive Bayes should be the fastest amongst the three of them. The generative training time is directly dependent on the size of the dataset, the number of tagging/linking rules, and epochs (which you can configure using the LearningConfig class. Adding tagging rules like the ones you just described will increase the search space, leading to an increased runtime.\n",
    "\n",
    "Adding training logging for the generative model has been on our TODO list for a while now. However, training a generative model for ~2 epochs can give you a rough approximation of its performance when using 5 epochs (I wouldn't expect the F1 score to increase by more than a few points).\n",
    "\n",
    "Here's the answer to your questions:\n",
    "\n",
    "    Accuracy vs coverage: High accuracy is generally associated with high precision, whereas high coverage is associated with high recall. While you should aim to strike a balance between the two types of rules, we recommend prioritizing precision over recall. This is because the discriminative neural network improves the generalization of the pipeline, and mainly provides increases in recall.\n",
    "    If a given set of rules has a high coverage but low accuracy, the quality of the probabilistic labels used to train the neural tagger will be low (low precision, high recall). Hence, the discriminative model will learn from a large number of partially incorrect labels and likely fail to generalize much beyond the information given. In such cases, it is preferable to have a smaller number of correct labels but increased accuracy (high precision, low recall). I personally recommend writing tagging and linking rules to get a precision of +70% and recall of +50%, but these values really depend on your end-goal and task.\n",
    "\n",
    "    Accuracy Prior vs Balance Prior: Good question! The typical search space for these two hyperparameters is [0, 500]. For our paper, we ran a grid search using the following values: {0.5, 1, 5, 10, 50, 100, 500}, but your model need not be limited to those. We generally think of the accuracy and balance prior as intensities, meaning that the exact numerical value of the regularizer sdoesn't matter as much as their proximity to 0 or 500. In our next updates, we will add a small note indicating the range of the generative hyperparameters.\n",
    "\n",
    "    Macro vs. Micro and F1: You're definitely correct in that entity recognition labels tend to always be a minority of the corpus. However, most sequence tagging papers we've based our work on report their scores using macro F1. Therefore, we have adopted this practice. Please feel free to share some sequence tagging papers and sample tasks that typically report scores using micro-F1.\n",
    "\n",
    "https://github.com/BatsResearch/wiser/blob/master/FAQ.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Previous Tagging Rules\n",
    "\n",
    "You can also develop more complex tagging rules by looking at previous tagging rule votes using the ``WISER_LABELS`` field. However, be mindful of the order in which you run the tagging functions.\n",
    "\n",
    "In the following example, we will write a tagging rule to identify performances based on adjacent tags such as ``series`` or ``show`` (e.g., ``The TV series The Mandalorian`` or ``Kung-Fu Panda franchise``). However, we also want to avoid tagging common false positives such as ``TV``), which is why we will reference the output votes of the ``CommonFalsePositives`` rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movie_keywords = {'trilogy', 'saga', 'series', 'miniseries', \n",
    "                'show', 'opera', 'drama', 'musical', 'sequel',\n",
    "                'prequel', 'franchise', 'thriller', 'sitcom'}\n",
    "\n",
    "class MovieKeywords(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        # List of tag votes of CommonFalsePositives rule\n",
    "        false_positives = [t for t in instance['WISER_LABELS']['CommonFalsePositives']]\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i].lower() in movie_keywords:\n",
    "                \"\"\"\n",
    "                    We will only tag a word as a movie if \n",
    "                    the CommonFalsePositives asbtained from voting it.\n",
    "                    \n",
    "                    We also want to avoid award names \n",
    "                    like \"... Musical Drama\", etc.\n",
    "                \"\"\" \n",
    "                \n",
    "                # Keywords followed by movies (e.g., Kung-Fu Panda franchise)\n",
    "                if i < len(tokens) and tokens[i+1].istitle() and false_positives[i+1] == 'ABS':\n",
    "                    if tokens[i+1].lower() not in movie_keywords:\n",
    "                        labels[i+1] = 'I-PERF'\n",
    "                       \n",
    "                # Movies followed by keywords \n",
    "                elif i > 0 and tokens[i-1].istitle() and false_positives[i-1] == 'ABS':\n",
    "                    if tokens[i-1].lower() not in movie_keywords:\n",
    "                        labels[i-1] = 'I-PERF'\n",
    "        return labels\n",
    "\n",
    "tr = MovieKeywords()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Existing Models\n",
    "\n",
    "WISER also allows us to implement existing machine learning systems to provide more accurate weak supervision. You can import existing classifiers or NLP tools to improve your current model.\n",
    "\n",
    "For our next tagging rule, we will use [spaCy's part-of-speech tagger](https://spacy.io/usage/linguistic-features#pos-tagging). This pre-trained model identifies sentence part-of-speech tags, and will be useful to identify many non-entity words such as lowercased nouns, verbs, and adjectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tagger = nlp.create_pipe(\"tagger\")\n",
    "\n",
    "non_entity_lowercases = {'NOUN', 'VERB', 'ADJ', 'SPACE', 'NUM'}\n",
    "\n",
    "class NonEntityWords(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        \n",
    "        # We obtain the parts-of-speech from SpaCy\n",
    "        parts_of_speech = [token[0].pos_ for token in nlp.pipe(tokens)]        \n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        for i, (token, pos) in enumerate(zip(tokens, parts_of_speech)):\n",
    "            if pos in non_entity_lowercases and not token.istitle():\n",
    "                labels[i] = 'O'\n",
    "                \n",
    "        return labels\n",
    "\n",
    "tr = NonEntityWords()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# TODO remove cd_connlu when moving to notebook\n",
    "nooj_tagged_file = \"/media/gaurish/angela/projects/nooj-grammer-negation/nooj-{0}.json\"\n",
    "\n",
    "# Opening JSON file\n",
    "with open(nooj_tagged_file.format(\"train\")) as file:\n",
    "    nooj_train_data = json.load(file)\n",
    "with open(nooj_tagged_file.format(\"dev\")) as file:\n",
    "    nooj_dev_data = json.load(file)\n",
    "with open(nooj_tagged_file.format(\"test\")) as file:\n",
    "    nooj_test_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ac06230a0449ecb5c052e44c88db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class NoojLabels(TaggingRule):\n",
    "    def apply_instance(self, instance):\n",
    "\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        labels = ['ABS'] * len(tokens)\n",
    "\n",
    "        # List of tag votes of CommonFalsePositives rule\n",
    "#         false_positives = [t for t in instance['WISER_LABELS']['CommonFalsePositives']]\n",
    "        nooj_data = []\n",
    "        key = \" \".join(tokens)\n",
    "\n",
    "        if key in nooj_train_data:\n",
    "            nooj_data = nooj_train_data[key]\n",
    "        elif key in nooj_dev_data:\n",
    "            nooj_data = nooj_dev_data[key]\n",
    "        elif key in nooj_test_data:\n",
    "            nooj_data = nooj_test_data[key]\n",
    "        if nooj_data:\n",
    "            for i in range(len(tokens)):\n",
    "                labels[i] = nooj_data[i]\n",
    "        return labels\n",
    "\n",
    "\n",
    "tr = NoojLabels()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Tagging Rules\n",
    "We can inspect the performance of individual tagging_rules by using the ``score_tagging_rules`` method. \n",
    "\n",
    "* True positives (TP) represent the number of items correctly labeled spans belonging to a positive class (e.g. **I-PERF**).\n",
    "\n",
    "* False positives (FP) are the number of items incorrectly labeled spans belonging to a positive class.\n",
    "\n",
    "* False Negatives (FN) are the items which were not labeled as belonging to the positive class but should have been.\n",
    "\n",
    "* Token Accuracy (Token Acc.) represents the fraction of issued votes that correctly identified a token in a positive class.\n",
    "\n",
    "* Token Votes is the total number of times the tagging rules issued a vote belonging to a positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Token Acc.</th>\n",
       "      <th>Token Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BigramNegationCueNT</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>406</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommonFalsePositives</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommonTruePositivesImplicitsCue</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommonTruePositivesImplicitsScope</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>426</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-EntityPunctuation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoojLabels</th>\n",
       "      <td>276</td>\n",
       "      <td>88</td>\n",
       "      <td>151</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrigramNegationCue</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>426</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    TP  FP   FN  Token Acc.  Token Votes\n",
       "BigramNegationCueNT                 21  17  406      1.0000           38\n",
       "CommonFalsePositives                 0   0  427      1.0000           10\n",
       "CommonTruePositivesImplicitsCue    140   5  287      0.9793          145\n",
       "CommonTruePositivesImplicitsScope    1  10  426      1.0000           11\n",
       "Non-EntityPunctuation                0   0  427      0.9458          295\n",
       "NoojLabels                         276  88  151      0.8033         2278\n",
       "TrigramNegationCue                   1   0  426      1.0000            3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiser.eval import score_tagging_rules\n",
    "score_tagging_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb is to write tagging rules whose accuracy is above 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Rules\n",
    "Linking rules are simple functions that vote on whether two or more adjacent tokens belong should belong to the same entity. To get started with linking rules, you can import the ``LinkingRule`` class from ``wiser.lf``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.rules import LinkingRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Linking Rules\n",
    "Tagging rules do not always correctly vote on *all* the tokens in multi-span entities. For instance, the **MovieYear** tagging rule only tags the last token in a movie span. Given the text span ``The Great Gatsby (2013)``, it only identifies the token ``Gatsby`` as **I-PERF**.\n",
    "\n",
    "Our job is to ensure that the entire class spans are tagged correctly. Therefore, we can start by writing a linking rule to indicate that consecutively capitalized words should share the same tag. Therefore, voting that ``The`` and ``Great`` share the same tag as ``Gatsby`` would tag the entire movie name as **I-PERF**, rather than the last token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ConsecutiveCapitals(LinkingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            if tokens[i].istitle() and tokens[i-1].istitle():\n",
    "                links[i] = 1 # token at index \"i\" shares tag with token at index \"i-1\"\n",
    "        return links\n",
    "\n",
    "lr = ConsecutiveCapitals()\n",
    "lr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data we have also observed several movie and award names that have hyphens, colons or semicolons (e.g. ``Avengers: Endgame``). We can write a linking rule to indicate that these linking punctuation characters, along with their preceding and succeeding tokens, should all be a part of the same entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linkers = {':', ';', '-'}\n",
    "\n",
    "class PunctuationLinkers(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)-1):\n",
    "            if tokens[i] in linkers:\n",
    "                \n",
    "                # The linking punctuation character and it's succeeding character\n",
    "                # share the same tag as the preceding one at index \"i-1\"\n",
    "                links[i] = 1\n",
    "                links[i+1] = 1\n",
    "        return links\n",
    "\n",
    "lr = PunctuationLinkers()\n",
    "lr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can write a rule to indicate that contractions share the same tag with the token preceding them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contraction_suffixes = {'\\'s', '\\'nt', '\\'ve', '\\'', '\\'d'}\n",
    "\n",
    "class Contractions(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            if tokens[i] in contraction_suffixes:\n",
    "                links[i] = 1\n",
    "        return links\n",
    "\n",
    "lr = Contractions()\n",
    "lr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also link noun phrases that using a list of common prepositions in award and movie names. These prepositions are part of award and movie names, and are usually lowercase and adjacent to or other prepositions or capitalized words. For example, ``Golden Globe for Best Actor`` or ``Guardians of the Galaxy``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_prepositions = {'a', 'the', 'at', 'with', 'of', 'by', '&', 'with'}\n",
    "\n",
    "class CommonPrepositions(LinkingRule):\n",
    "\n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        links = [0] * len(tokens)\n",
    "        \n",
    "        for i in range(1, len(tokens)-1):\n",
    "            if tokens[i] in common_prepositions:\n",
    "                if tokens[i-1].istitle() or tokens[i-1] in common_prepositions:\n",
    "                    if tokens[i+1].istitle() or tokens[i+1] in common_prepositions:\n",
    "                        links[i] = 1\n",
    "                        links[i+1] = 1\n",
    "        return links\n",
    "\n",
    "lr = CommonPrepositions()\n",
    "lr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Rule Helpers\n",
    "\n",
    "Similar to tagging rules, we have linking rule helpers available at ``wiser.rules``. For the next linking rule, we will use the ``ElmoLinkingRule``, a rule that vectorizes tokens using [Elmo](https://allennlp.org/elmo) and links those with a cosine similaritiy larger than a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiser.rules import ElmoLinkingRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ea5505ea2444f69802a3231cc2d968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Links tokens whose cosine similarity is larger than 0.8\n",
    "lr = ElmoLinkingRule(0.8)\n",
    "lr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Linking Rules\n",
    "\n",
    "Similar to tagging rules, we can evaluate the accuracy of our linking rules using the ``score_linking_functions`` method.\n",
    "\n",
    "* Entity Links represents the number of correct links generated for positive classes.\n",
    "* Non-Entity Links represents the number of correct links generated for negative classes (e.g., **O** tags).\n",
    "* Incorrect links represent the total number of incorrectly generated links.\n",
    "* Accuracy represents the fraction of issued links that identified correct links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Links</th>\n",
       "      <th>Non-Entity Links</th>\n",
       "      <th>Incorrect Links</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ElmoLinkingRule</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Entity Links  Non-Entity Links  Incorrect Links  Accuracy\n",
       "ElmoLinkingRule             0                 1                0       1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiser.eval import score_linking_rules\n",
    "score_linking_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, a good rule of thumb is to have all linking rules with an accuracy above 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Tagging and Linking Rules\n",
    "When developing sequence tagging pipelines, you will often need to remove tagging or linking rules you've previously applied to the data. The ``rules.remove_rule`` method deletes all occurrences of a tagging or linking rule vote in a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from wiser.rules import remove_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how the ``remove_rule`` method works, let's first create a dummy tagging rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DummyRule(TaggingRule):\n",
    "    \n",
    "    def apply_instance(self, instance):\n",
    "        tokens = [t.text for t in instance['tokens']]\n",
    "        return ['ABS'] * len(tokens)\n",
    "        \n",
    "tr = DummyRule()\n",
    "tr.apply(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that this rule has been applied to the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Token Acc.</th>\n",
       "      <th>Token Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BigramNegationCueNT</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>406</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommonFalsePositives</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommonTruePositivesImplicitsCue</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommonTruePositivesImplicitsScope</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>426</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-EntityPunctuation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoojLabels</th>\n",
       "      <td>276</td>\n",
       "      <td>88</td>\n",
       "      <td>151</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrigramNegationCue</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>426</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    TP  FP   FN  Token Acc.  Token Votes\n",
       "BigramNegationCueNT                 21  17  406      1.0000           38\n",
       "CommonFalsePositives                 0   0  427      1.0000           10\n",
       "CommonTruePositivesImplicitsCue    140   5  287      0.9793          145\n",
       "CommonTruePositivesImplicitsScope    1  10  426      1.0000           11\n",
       "Non-EntityPunctuation                0   0  427      0.9458          295\n",
       "NoojLabels                         276  88  151      0.8033         2278\n",
       "TrigramNegationCue                   1   0  426      1.0000            3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tagging_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the rule name to the ``remove_rule`` method will eliminate it from the given dataset. This step can also be applied to linking rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove_rule(data, 'DummyRule') # Don't forget to pass the entire dataset\n",
    "score_tagging_rules(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Progress\n",
    "We can use pickle to store the data with the tagging and linking rules applied to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory output/tmp: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir output/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('output/tmp/train_data.p', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open('output/tmp/dev_data.p', 'wb') as f:\n",
    "    pickle.dump(dev_data, f)\n",
    "\n",
    "with open('output/tmp/test_data.p', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed part 1! Now you can move on to part 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
